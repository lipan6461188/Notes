查看GPU的版本：

```shell
lspci | grep NVIDIA
# 老的设备
# 06:00.0 3D controller: NVIDIA Corporation GK210GL [Tesla K80] (rev a1)
# 新的设备
# 1a:00.2 USB controller: NVIDIA Corporation Device 1ad6 (rev a1)

lshw -C display
#WARNING: you should run this program as super-user.
#  *-display
#       description: VGA compatible controller
#       product: ASPEED Graphics Family
#       vendor: ASPEED Technology, Inc.
#       physical id: 0
#       bus info: pci@0000:03:00.0
#       version: 41
#       width: 32 bits
#       clock: 33MHz
#       capabilities: vga_controller cap_list rom
#       configuration: driver=ast latency=0
#       resources: irq:17 memory:9c000000-9cffffff memory:9d000000-9d01ffff #ioport:1000(size=128)

nvidia-smi -L
# GPU 0: Tesla K80 (UUID: GPU-81bc737f-b8c8-a769-bb37-4cb60c3d395c)
# GPU 0: GeForce RTX 2080 Ti (UUID: GPU-f77c742c-bc54-eb96-9fb9-b578595fa465)
```

创建一个新的环境，并安装tensorflow和torch

```shell
python -m venv myenv
```

使用环境

```shell
source myenv/bin/activate
export PIP_TARGET=/home/lipan/myenv/lib/python3.7/site-packages
export PYTHONPATH=/home/lipan/usr/IPyRSSA:/home/lipan/usr/GAP
```

分别设置CUDA和cuDNN：

```shell
export LD_LIBRARY_PATH=/home/lipan/usr/cuda-10.0/lib64:$LD_LIBRARY_PATH
export LD_LIBRARY_PATH=/home/lipan/usr/cudnn/lib64:$LD_LIBRARY_PATH
```

安装torch和tensorflow

```shell
pip install tensorflow
pip install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio==0.8.1 -f https://download.pytorch.org/whl/torch_stable.html
```

测试torch和tensorflow是否可以使用GPU：

```python
# 首先记得不要设置这个环境变量
# unset CUDA_VISIBLE_DEVICES

import tensorflow
tensorflow.config.experimental.list_physical_devices("GPU")
# [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:4', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:5', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:6', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:7', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:8', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:9', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:10', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:11', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:12', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:13', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:14', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:15', device_type='GPU')]

import torch
torch.cuda.is_available()
# True
torch.cuda.device_count()
# 16
```

CUDA的常用命令

```shell
nvidia-smi -L # 列出所有GPU的型号
nvidia-smi pmon -i 0 # 监测0号GPU的运行状态
nvidia-smi -q # 显示GPU的详细信息，
```

Page 187

